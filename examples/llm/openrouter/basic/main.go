package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"time"

	"github.com/ynl/greensoulai/internal/llm"
)

func main() {
	fmt.Println("ğŸŒ OpenRouter LLM åŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
	fmt.Println("===============================")

	// OpenRouter APIé…ç½®
	// ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç¤ºä¾‹Key
	apiKey := os.Getenv("OPENROUTER_API_KEY")
	if apiKey == "" {
		apiKey = ""
		fmt.Println("âš ï¸  ä½¿ç”¨ç¤ºä¾‹API Keyï¼Œå»ºè®®è®¾ç½®ç¯å¢ƒå˜é‡ OPENROUTER_API_KEY")
	}

	baseURL := "https://openrouter.ai/api/v1"
	model := "moonshotai/kimi-k2:free" // ä½¿ç”¨å…è´¹çš„Kimiæ¨¡å‹

	fmt.Printf("ğŸ”‘ API Key: %s...\n", apiKey[:20])
	fmt.Printf("ğŸŒ Base URL: %s\n", baseURL)
	fmt.Printf("ğŸ¤– Model: %s\n", model)

	// åˆ›å»ºLLMé…ç½®
	config := &llm.Config{
		Provider:    "openai", // ä½¿ç”¨OpenAIæä¾›å•†ï¼Œå› ä¸ºOpenRouterå…¼å®¹OpenAI API
		Model:       model,
		APIKey:      apiKey,
		BaseURL:     baseURL,
		Timeout:     30 * time.Second,
		MaxRetries:  3,
		Temperature: func() *float64 { t := 0.7; return &t }(),
		MaxTokens:   func() *int { t := 1000; return &t }(),
	}

	// åˆ›å»ºLLMå®ä¾‹å¹¶æ·»åŠ OpenRouterç‰¹å®šçš„headers
	llmInstance, err := llm.CreateLLM(config)
	if err != nil {
		log.Fatalf("âŒ åˆ›å»ºLLMå¤±è´¥: %v", err)
	}
	defer llmInstance.Close()

	// å¦‚æœéœ€è¦æ·»åŠ OpenRouterçš„å¯é€‰headersï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ï¼š
	// æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦åœ¨åˆ›å»ºæ—¶å°±æ·»åŠ è‡ªå®šä¹‰headers
	openaiLLM := llm.NewOpenAILLM(model,
		llm.WithAPIKey(apiKey),
		llm.WithBaseURL(baseURL),
		llm.WithTimeout(30*time.Second),
		llm.WithMaxRetries(3),
		llm.WithCustomHeader("HTTP-Referer", "https://github.com/ynl/greensoulai"),
		llm.WithCustomHeader("X-Title", "GreenSoulAI"),
	)

	fmt.Printf("âœ… æˆåŠŸåˆ›å»º %s æ¨¡å‹å®ä¾‹\n", openaiLLM.GetModel())
	fmt.Printf("ğŸ¯ æ”¯æŒå‡½æ•°è°ƒç”¨: %v\n", openaiLLM.SupportsFunctionCalling())
	fmt.Printf("ğŸ“ ä¸Šä¸‹æ–‡çª—å£: %d tokens\n", openaiLLM.GetContextWindowSize())

	// æµ‹è¯•åŸºç¡€å¯¹è¯
	fmt.Println("\nğŸ“ åŸºç¡€å¯¹è¯æµ‹è¯•:")
	messages := []llm.Message{
		{Role: llm.RoleSystem, Content: "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚"},
		{Role: llm.RoleUser, Content: "ä»€ä¹ˆæ˜¯äººç”Ÿçš„æ„ä¹‰ï¼Ÿè¯·ç®€çŸ­å›ç­”ã€‚"},
	}

	ctx := context.Background()
	response, err := openaiLLM.Call(ctx, messages, &llm.CallOptions{
		Temperature: func() *float64 { t := 0.5; return &t }(),
		MaxTokens:   func() *int { t := 200; return &t }(),
	})

	if err != nil {
		fmt.Printf("âŒ è°ƒç”¨å¤±è´¥: %v\n", err)

		// å°è¯•è¯Šæ–­é—®é¢˜
		fmt.Println("\nğŸ” è¯Šæ–­ä¿¡æ¯:")
		fmt.Printf("- API Key é•¿åº¦: %d\n", len(apiKey))
		fmt.Printf("- Base URL: %s\n", baseURL)
		fmt.Printf("- Model: %s\n", model)

		return
	}

	fmt.Printf("ğŸ¤– å›å¤: %s\n", response.Content)
	fmt.Printf("ğŸ“Š ä½¿ç”¨ç»Ÿè®¡:\n")
	fmt.Printf("   - æ€»Token: %d\n", response.Usage.TotalTokens)
	fmt.Printf("   - æç¤ºToken: %d\n", response.Usage.PromptTokens)
	fmt.Printf("   - å®ŒæˆToken: %d\n", response.Usage.CompletionTokens)
	fmt.Printf("   - é¢„ä¼°æˆæœ¬: $%.6f\n", response.Usage.Cost)
	fmt.Printf("   - æ¨¡å‹: %s\n", response.Model)
	fmt.Printf("   - ç»“æŸåŸå› : %s\n", response.FinishReason)

	// æµ‹è¯•æµå¼å“åº”
	fmt.Println("\nğŸŒŠ æµå¼å“åº”æµ‹è¯•:")
	streamMessages := []llm.Message{
		{Role: llm.RoleUser, Content: "è¯·ç”¨ä¸€å¥è¯ä»‹ç»Goè¯­è¨€çš„ç‰¹ç‚¹ã€‚"},
	}

	stream, err := openaiLLM.CallStream(ctx, streamMessages, &llm.CallOptions{
		Temperature: func() *float64 { t := 0.7; return &t }(),
		MaxTokens:   func() *int { t := 100; return &t }(),
	})

	if err != nil {
		fmt.Printf("âŒ æµå¼è°ƒç”¨å¤±è´¥: %v\n", err)
	} else {
		fmt.Print("ğŸ¤– æµå¼å›å¤: ")
		fullResponse := ""
		for chunk := range stream {
			if chunk.Error != nil {
				fmt.Printf("\nâŒ æµå¼é”™è¯¯: %v\n", chunk.Error)
				break
			}
			fmt.Print(chunk.Delta)
			fullResponse += chunk.Delta

			// å¦‚æœæœ‰ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯ï¼Œæ˜¾ç¤º
			if chunk.Usage != nil {
				fmt.Printf("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡: %d tokens\n", chunk.Usage.TotalTokens)
			}
		}
		fmt.Printf("\nâœ… æµå¼å“åº”å®Œæˆï¼Œæ€»é•¿åº¦: %d å­—ç¬¦\n", len(fullResponse))
	}

	// æµ‹è¯•ä¸åŒæ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	fmt.Println("\nğŸ”„ å¤šæ¨¡å‹æµ‹è¯•:")
	models := []string{
		"moonshotai/kimi-k2:free",
		"openai/gpt-3.5-turbo",
		"anthropic/claude-3-haiku",
	}

	for _, testModel := range models {
		fmt.Printf("\nğŸ§ª æµ‹è¯•æ¨¡å‹: %s\n", testModel)

		testLLM := llm.NewOpenAILLM(testModel,
			llm.WithAPIKey(apiKey),
			llm.WithBaseURL(baseURL),
			llm.WithTimeout(10*time.Second),
			llm.WithMaxRetries(1),
			llm.WithCustomHeader("HTTP-Referer", "https://github.com/ynl/greensoulai"),
			llm.WithCustomHeader("X-Title", "GreenSoulAI"),
		)

		testResponse, err := testLLM.Call(ctx, []llm.Message{
			{Role: llm.RoleUser, Content: "Hi, just say hello in one word."},
		}, &llm.CallOptions{
			MaxTokens: func() *int { t := 10; return &t }(),
		})

		if err != nil {
			fmt.Printf("   âŒ å¤±è´¥: %v\n", err)
		} else {
			fmt.Printf("   âœ… æˆåŠŸ: %s\n", testResponse.Content)
		}
	}

	fmt.Println("\nğŸ‰ OpenRouter é›†æˆæµ‹è¯•å®Œæˆï¼")
	fmt.Println("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
	fmt.Println("   âœ… æ”¯æŒè‡ªå®šä¹‰Base URL")
	fmt.Println("   âœ… æ”¯æŒè‡ªå®šä¹‰API Key")
	fmt.Println("   âœ… æ”¯æŒè‡ªå®šä¹‰HTTP Headers")
	fmt.Println("   âœ… å…¼å®¹OpenAI APIæ ¼å¼")
	fmt.Println("   âœ… æ”¯æŒåŒæ­¥å’Œæµå¼è°ƒç”¨")
	fmt.Println("   âœ… æ”¯æŒå¤šç§æ¨¡å‹")

	fmt.Println("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
	fmt.Println("   1. ç¡®ä¿API Keyæœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿä½™é¢")
	fmt.Println("   2. é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼ˆå…è´¹æˆ–ä»˜è´¹ï¼‰")
	fmt.Println("   3. è®¾ç½®é€‚å½“çš„è¶…æ—¶å’Œé‡è¯•")
	fmt.Println("   4. ç›‘æ§Tokenä½¿ç”¨å’Œæˆæœ¬")
}
