// æ¼”ç¤ºå·¥ä½œæµçŠ¶æ€ä¼ é€’çš„å®Œæ•´ç¤ºä¾‹
// å±•ç¤ºå¦‚ä½•åœ¨ä½œä¸šé—´ä¼ é€’å’Œå…±äº«æ•°æ®
package main

import (
	"context"
	"fmt"
	"time"

	"github.com/ynl/greensoulai/pkg/flow"
)

func main() {
	fmt.Println("ğŸ”„ **å·¥ä½œæµçŠ¶æ€ä¼ é€’æ¼”ç¤º**")
	fmt.Println("   å±•ç¤ºä½œä¸šé—´å¦‚ä½•ä¼ é€’å’Œå…±äº«æ•°æ®")
	fmt.Println()

	// åˆ›å»ºå·¥ä½œæµ
	workflow := flow.NewWorkflow("stateful-processing")

	// 1. æ•°æ®æ”¶é›†ä½œä¸š - å°†æ•°æ®å­˜å‚¨åˆ°çŠ¶æ€ä¸­
	dataCollectionJob := flow.NewStatefulJob("data-collection", func(ctx context.Context, state flow.FlowState) (interface{}, error) {
		fmt.Println("   ğŸ“¥ æ”¶é›†æ•°æ®...")
		time.Sleep(100 * time.Millisecond)

		// å°†æ”¶é›†çš„æ•°æ®å­˜å‚¨åˆ°å·¥ä½œæµçŠ¶æ€ä¸­
		rawData := []string{"ç”¨æˆ·è¯„è®º1", "ç”¨æˆ·è¯„è®º2", "ç”¨æˆ·è¯„è®º3", "äº§å“æè¿°"}
		// è½¬æ¢ä¸º[]interface{}ä»¥ä¾¿åç»­ä½¿ç”¨GetSliceæ–¹æ³•
		rawDataInterface := make([]interface{}, len(rawData))
		for i, v := range rawData {
			rawDataInterface[i] = v
		}
		state.Set("raw_data", rawDataInterface)
		state.Set("data_count", len(rawData))
		state.Set("collection_time", time.Now())

		fmt.Printf("   ğŸ“¦ å·²æ”¶é›† %d æ¡æ•°æ®å¹¶å­˜å‚¨åˆ°çŠ¶æ€ä¸­\n", len(rawData))
		return fmt.Sprintf("æ”¶é›†äº†%dæ¡æ•°æ®", len(rawData)), nil
	})

	// 2. æ•°æ®æ¸…æ´—ä½œä¸š - ä»çŠ¶æ€ä¸­è¯»å–æ•°æ®ï¼Œæ¸…æ´—åæ›´æ–°çŠ¶æ€
	dataCleaningJob := flow.NewStatefulJob("data-cleaning", func(ctx context.Context, state flow.FlowState) (interface{}, error) {
		fmt.Println("   ğŸ§¹ æ¸…æ´—æ•°æ®...")
		time.Sleep(80 * time.Millisecond)

		// ä»çŠ¶æ€ä¸­è·å–åŸå§‹æ•°æ®
		rawData, exists := state.GetSlice("raw_data")
		if !exists {
			return nil, fmt.Errorf("æœªæ‰¾åˆ°åŸå§‹æ•°æ®")
		}

		// æ¨¡æ‹Ÿæ•°æ®æ¸…æ´—
		cleanedData := make([]string, 0)
		for _, item := range rawData {
			if str, ok := item.(string); ok && len(str) > 0 {
				cleaned := fmt.Sprintf("[å·²æ¸…æ´—] %s", str)
				cleanedData = append(cleanedData, cleaned)
			}
		}

		// å°†æ¸…æ´—åçš„æ•°æ®å­˜å‚¨å›çŠ¶æ€ï¼ˆè½¬æ¢ä¸º[]interface{}ï¼‰
		cleanedDataInterface := make([]interface{}, len(cleanedData))
		for i, v := range cleanedData {
			cleanedDataInterface[i] = v
		}
		state.Set("cleaned_data", cleanedDataInterface)
		state.Set("cleaning_time", time.Now())

		fmt.Printf("   âœ¨ å·²æ¸…æ´— %d æ¡æ•°æ®\n", len(cleanedData))
		return fmt.Sprintf("æ¸…æ´—äº†%dæ¡æ•°æ®", len(cleanedData)), nil
	})

	// 3. è´¨é‡åˆ†æä½œä¸š - åŸºäºæ¸…æ´—åçš„æ•°æ®è¿›è¡Œåˆ†æ
	qualityAnalysisJob := flow.NewStatefulJob("quality-analysis", func(ctx context.Context, state flow.FlowState) (interface{}, error) {
		fmt.Println("   ğŸ” è´¨é‡åˆ†æ...")
		time.Sleep(120 * time.Millisecond)

		// ä»çŠ¶æ€ä¸­è·å–æ¸…æ´—åçš„æ•°æ®
		cleanedData, exists := state.GetSlice("cleaned_data")
		if !exists {
			return nil, fmt.Errorf("æœªæ‰¾åˆ°æ¸…æ´—åçš„æ•°æ®")
		}

		// æ¨¡æ‹Ÿè´¨é‡åˆ†æ
		qualityScore := float64(len(cleanedData)) * 20.5 // ç®€å•çš„è´¨é‡è¯„åˆ†é€»è¾‘

		// å°†åˆ†æç»“æœå­˜å‚¨åˆ°çŠ¶æ€
		state.Set("quality_score", qualityScore)
		state.Set("quality_analysis_time", time.Now())

		analysisResult := fmt.Sprintf("è´¨é‡è¯„åˆ†: %.1f%%", qualityScore)
		fmt.Printf("   ğŸ“Š %s\n", analysisResult)
		return analysisResult, nil
	})

	// 4. æƒ…æ„Ÿåˆ†æä½œä¸š - åŒæ—¶åŸºäºæ¸…æ´—åçš„æ•°æ®è¿›è¡Œåˆ†æ
	sentimentAnalysisJob := flow.NewStatefulJob("sentiment-analysis", func(ctx context.Context, state flow.FlowState) (interface{}, error) {
		fmt.Println("   ğŸ˜Š æƒ…æ„Ÿåˆ†æ...")
		time.Sleep(100 * time.Millisecond)

		// ä»çŠ¶æ€ä¸­è·å–æ¸…æ´—åçš„æ•°æ®
		cleanedData, exists := state.GetSlice("cleaned_data")
		if !exists {
			return nil, fmt.Errorf("æœªæ‰¾åˆ°æ¸…æ´—åçš„æ•°æ®")
		}

		// æ¨¡æ‹Ÿæƒ…æ„Ÿåˆ†æ
		positiveCount := 0
		for _, item := range cleanedData {
			if str, ok := item.(string); ok && len(str) > 10 { // ç®€å•é€»è¾‘ï¼šé•¿æ–‡æœ¬å€¾å‘æ­£é¢
				positiveCount++
			}
		}

		positiveRatio := float64(positiveCount) / float64(len(cleanedData)) * 100

		// å°†åˆ†æç»“æœå­˜å‚¨åˆ°çŠ¶æ€
		state.Set("positive_ratio", positiveRatio)
		state.Set("sentiment_analysis_time", time.Now())

		sentimentResult := fmt.Sprintf("æ­£é¢æƒ…æ„Ÿ: %.1f%%", positiveRatio)
		fmt.Printf("   ğŸ’š %s\n", sentimentResult)
		return sentimentResult, nil
	})

	// 5. æŠ¥å‘Šç”Ÿæˆä½œä¸š - æ±‡æ€»æ‰€æœ‰åˆ†æç»“æœ
	reportGenerationJob := flow.NewStatefulJob("report-generation", func(ctx context.Context, state flow.FlowState) (interface{}, error) {
		fmt.Println("   ğŸ“ ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
		time.Sleep(60 * time.Millisecond)

		// ä»çŠ¶æ€ä¸­è·å–æ‰€æœ‰åˆ†æç»“æœ
		dataCount, _ := state.GetInt("data_count")
		qualityScore, _ := state.GetFloat64("quality_score")
		positiveRatio, _ := state.GetFloat64("positive_ratio")
		collectionTime, _ := state.Get("collection_time")

		// ç”Ÿæˆç»¼åˆæŠ¥å‘Š
		report := fmt.Sprintf(`
ğŸ“‹ **æ•°æ®åˆ†æç»¼åˆæŠ¥å‘Š**
   â€¢ æ•°æ®é‡: %d æ¡
   â€¢ è´¨é‡è¯„åˆ†: %.1f%%
   â€¢ æ­£é¢æƒ…æ„Ÿæ¯”ä¾‹: %.1f%%
   â€¢ æ”¶é›†æ—¶é—´: %v
   â€¢ å¤„ç†çŠ¶æ€: å®Œæˆ`,
			dataCount, qualityScore, positiveRatio, collectionTime)

		// å°†æœ€ç»ˆæŠ¥å‘Šå­˜å‚¨åˆ°çŠ¶æ€
		state.Set("final_report", report)
		state.Set("generation_time", time.Now())

		fmt.Println("   ğŸ“Š ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ")
		return "ç»¼åˆåˆ†ææŠ¥å‘Šå·²å®Œæˆ", nil
	})

	// æ„å»ºå·¥ä½œæµ - å±•ç¤ºå¤æ‚çš„ä¾èµ–å…³ç³»
	workflow.
		AddJob(dataCollectionJob, flow.Immediately()).                                        // 1. é¦–å…ˆæ”¶é›†æ•°æ®
		AddJob(dataCleaningJob, flow.After("data-collection")).                               // 2. åŸºäºæ”¶é›†çš„æ•°æ®è¿›è¡Œæ¸…æ´—
		AddJob(qualityAnalysisJob, flow.After("data-cleaning")).                              // 3. åŸºäºæ¸…æ´—æ•°æ®å¹¶è¡Œåˆ†æ
		AddJob(sentimentAnalysisJob, flow.After("data-cleaning")).                            // 4. åŸºäºæ¸…æ´—æ•°æ®å¹¶è¡Œåˆ†æ
		AddJob(reportGenerationJob, flow.AfterJobs("quality-analysis", "sentiment-analysis")) // 5. ç­‰å¾…æ‰€æœ‰åˆ†æå®Œæˆ

	fmt.Println("   ğŸš€ æ‰§è¡Œå¸¦çŠ¶æ€ä¼ é€’çš„å·¥ä½œæµ...")
	start := time.Now()

	// æ‰§è¡Œå·¥ä½œæµ
	result, err := workflow.Run(context.Background())
	totalTime := time.Since(start)

	if err != nil {
		fmt.Printf("âŒ æ‰§è¡Œå¤±è´¥: %v\n", err)
		return
	}

	fmt.Printf("\n   âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼\n")
	fmt.Printf("   ğŸ“Š æœ€ç»ˆç»“æœ: %s\n", result.FinalResult)
	fmt.Printf("   â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: %v\n", totalTime)
	fmt.Printf("   ğŸ”¢ æ€»ä½œä¸šæ•°: %d\n", result.Metrics.TotalJobs)
	fmt.Printf("   ğŸ“¦ å¹¶è¡Œæ‰¹æ¬¡æ•°: %d\n", result.Metrics.ParallelBatches)
	fmt.Printf("   ğŸš€ æœ€å¤§å¹¶å‘æ•°: %d\n", result.Metrics.MaxConcurrency)

	fmt.Printf("\n   ğŸ—‚ï¸ **æœ€ç»ˆå·¥ä½œæµçŠ¶æ€**:\n")
	finalState := result.FinalState
	for _, key := range finalState.Keys() {
		if value, exists := finalState.Get(key); exists {
			fmt.Printf("   â€¢ %s: %v\n", key, value)
		}
	}

	fmt.Printf("\n   ğŸ“‹ **æ‰§è¡Œè½¨è¿¹** (å±•ç¤ºçŠ¶æ€ä¼ é€’è¿‡ç¨‹):\n")
	for i, trace := range result.JobTrace {
		fmt.Printf("   %d. %s (æ‰¹æ¬¡%d): %v\n",
			i+1, trace.JobID, trace.BatchID, trace.Duration)
	}

	fmt.Printf("\n   âœ¨ **çŠ¶æ€ä¼ é€’äº®ç‚¹**:\n")
	fmt.Printf("   â€¢ æ•°æ®åœ¨ä½œä¸šé—´æ— ç¼ä¼ é€’\n")
	fmt.Printf("   â€¢ æ”¯æŒå¹¶å‘å®‰å…¨çš„çŠ¶æ€è®¿é—®\n")
	fmt.Printf("   â€¢ æä¾›ç±»å‹å®‰å…¨çš„çŠ¶æ€è·å–æ–¹æ³•\n")
	fmt.Printf("   â€¢ å®Œæ•´ä¿ç•™å·¥ä½œæµæ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ‰€æœ‰çŠ¶æ€\n")
	fmt.Printf("   â€¢ å‘ä¸‹å…¼å®¹ï¼šæ™®é€šJobæ— éœ€ä¿®æ”¹å³å¯ä½¿ç”¨\n")

	fmt.Printf("\n   ğŸ”§ **æŠ€æœ¯ç‰¹æ€§**:\n")
	fmt.Printf("   â€¢ FlowState: çº¿ç¨‹å®‰å…¨çš„çŠ¶æ€å­˜å‚¨\n")
	fmt.Printf("   â€¢ StatefulJob: æ”¯æŒçŠ¶æ€ä¼ é€’çš„ä½œä¸šæ¥å£\n")
	fmt.Printf("   â€¢ è‡ªåŠ¨é€‚é…: æ™®é€šJobå’ŒStatefulJobæ··åˆä½¿ç”¨\n")
	fmt.Printf("   â€¢ çŠ¶æ€æŒä¹…åŒ–: æ‰§è¡Œå®ŒæˆåçŠ¶æ€å®Œæ•´ä¿ç•™\n")
}
