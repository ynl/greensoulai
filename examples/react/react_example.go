package main

import (
	"context"
	"fmt"
	"time"

	"github.com/ynl/greensoulai/internal/agent"
	"github.com/ynl/greensoulai/internal/llm"
	"github.com/ynl/greensoulai/pkg/events"
	"github.com/ynl/greensoulai/pkg/logger"
)

// è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨greensoulaiçš„ReActæ¨¡å¼
func main() {
	// 1. åˆ›å»ºå¿…è¦çš„ç»„ä»¶
	eventBus := events.NewEventBus(logger.NewConsoleLogger())
	agentLogger := logger.NewConsoleLogger()

	// 2. åˆ›å»ºLLMå®ä¾‹ï¼ˆè¿™é‡Œä½¿ç”¨æ¨¡æ‹ŸLLMï¼Œå®é™…ä½¿ç”¨ä¸­åº”è¯¥æ˜¯çœŸå®çš„LLMï¼‰
	mockLLM := createMockLLM()

	// 3. é…ç½®Agentä½¿ç”¨ReActæ¨¡å¼
	config := agent.AgentConfig{
		Role:      "Research Assistant",
		Goal:      "Help users conduct thorough research and analysis",
		Backstory: "I am a knowledgeable research assistant with expertise in analysis and investigation",
		LLM:       mockLLM,
		EventBus:  eventBus,
		Logger:    agentLogger,
		ExecutionConfig: agent.ExecutionConfig{
			MaxIterations:    15,
			MaxRPM:           60,
			Timeout:          30 * time.Minute,
			MaxExecutionTime: 10 * time.Minute,
			AllowDelegation:  false,
			VerboseLogging:   true,
			HumanInput:       false,
			UseSystemPrompt:  true,
			MaxTokens:        4096,
			Temperature:      0.7,
			CacheEnabled:     true,
			MaxRetryLimit:    3,
			Mode:             agent.ModeReAct, // å¯ç”¨ReActæ¨¡å¼
			ReActConfig: &agent.ReActConfig{
				MaxIterations:          10,
				ThoughtTimeout:         30 * time.Second,
				EnableDebugOutput:      true,
				StrictFormatValidation: true,
				AllowFallbackToJSON:    true,
			},
		},
	}

	// 4. åˆ›å»ºAgent
	myAgent, err := agent.NewBaseAgent(config)
	if err != nil {
		panic(fmt.Sprintf("Failed to create agent: %v", err))
	}

	// 5. æ·»åŠ å·¥å…·ï¼ˆå¯é€‰ï¼‰
	calculatorTool := agent.NewCalculatorTool()
	if err := myAgent.AddTool(calculatorTool); err != nil {
		panic(fmt.Sprintf("Failed to add tool: %v", err))
	}

	// 6. åˆ›å»ºä»»åŠ¡
	task := agent.NewBaseTask(
		"ç ”ç©¶äººå·¥æ™ºèƒ½åœ¨2024å¹´çš„å‘å±•è¶‹åŠ¿ï¼Œå¹¶åˆ†æå…¶å¯¹æœªæ¥5å¹´æŠ€æœ¯å‘å±•çš„å½±å“",
		"æä¾›ä¸€ä»½è¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«å…·ä½“æ•°æ®å’Œè¶‹åŠ¿åˆ†æ",
	)

	// 7. ä½¿ç”¨ReActæ¨¡å¼æ‰§è¡Œä»»åŠ¡
	ctx := context.Background()

	fmt.Println("ğŸ¤– å¯åŠ¨ReActæ¨¡å¼æ‰§è¡Œ...")
	fmt.Println("====================================================")

	output, trace, err := myAgent.ExecuteWithReAct(ctx, task)
	if err != nil {
		panic(fmt.Sprintf("Task execution failed: %v", err))
	}

	// 8. æ˜¾ç¤ºç»“æœ
	fmt.Println("\nğŸ“Š æ‰§è¡Œç»“æœ:")
	fmt.Printf("æœ€ç»ˆç­”æ¡ˆ: %s\n", output.Raw)
	fmt.Printf("æ‰§è¡Œæ—¶é—´: %v\n", output.ExecutionTime)
	fmt.Printf("æ¨¡å¼: %s\n", output.Metadata["mode"])

	fmt.Println("\nğŸ” ReActè½¨è¿¹:")
	for i, step := range trace.Steps {
		fmt.Printf("\næ­¥éª¤ %d:\n", i+1)
		fmt.Printf("  æ€è€ƒ: %s\n", step.Thought)
		if step.Action != "" {
			fmt.Printf("  åŠ¨ä½œ: %s\n", step.Action)
			fmt.Printf("  è¾“å…¥: %v\n", step.ActionInput)
			fmt.Printf("  è§‚å¯Ÿ: %s\n", step.Observation)
		}
		if step.FinalAnswer != "" {
			fmt.Printf("  æœ€ç»ˆç­”æ¡ˆ: %s\n", step.FinalAnswer)
		}
		if step.Error != "" {
			fmt.Printf("  é”™è¯¯: %s\n", step.Error)
		}
	}

	fmt.Printf("\nâœ… æ€»æ­¥éª¤æ•°: %d\n", trace.IterationCount)
	fmt.Printf("æ€»è€—æ—¶: %v\n", trace.TotalDuration)
	fmt.Printf("å®ŒæˆçŠ¶æ€: %v\n", trace.IsCompleted)

	// 9. æ¼”ç¤ºæ¨¡å¼åˆ‡æ¢
	fmt.Println("\nğŸ”„ æ¼”ç¤ºæ¨¡å¼åˆ‡æ¢:")
	fmt.Printf("å½“å‰æ¨¡å¼: %s\n", myAgent.GetCurrentMode().String())

	// åˆ‡æ¢åˆ°JSONæ¨¡å¼
	myAgent.SetReActMode(false)
	fmt.Printf("åˆ‡æ¢åæ¨¡å¼: %s\n", myAgent.GetCurrentMode().String())

	// åˆ‡æ¢å›ReActæ¨¡å¼
	myAgent.SetReActMode(true)
	fmt.Printf("å†æ¬¡åˆ‡æ¢åæ¨¡å¼: %s\n", myAgent.GetCurrentMode().String())

	// 10. å±•ç¤ºç»Ÿè®¡ä¿¡æ¯
	stats := myAgent.GetExecutionStats()
	fmt.Println("\nğŸ“ˆ Agentæ‰§è¡Œç»Ÿè®¡:")
	fmt.Printf("æ€»æ‰§è¡Œæ¬¡æ•°: %d\n", stats.TotalExecutions)
	fmt.Printf("æˆåŠŸæ¬¡æ•°: %d\n", stats.SuccessfulExecutions)
	fmt.Printf("å¤±è´¥æ¬¡æ•°: %d\n", stats.FailedExecutions)
	fmt.Printf("å¹³å‡æ‰§è¡Œæ—¶é—´: %v\n", stats.AverageExecutionTime)

	fmt.Println("\nğŸ‰ ReActæ¨¡å¼æ¼”ç¤ºå®Œæˆ!")
}

// createMockLLM åˆ›å»ºç”¨äºæ¼”ç¤ºçš„æ¨¡æ‹ŸLLM
func createMockLLM() llm.LLM {
	// è¿™é‡Œåˆ›å»ºä¸€ä¸ªæ¨¡æ‹ŸLLMï¼Œå®é™…ä½¿ç”¨ä¸­åº”è¯¥æ˜¯çœŸå®çš„LLMå®ç°
	responses := []llm.Response{
		{
			Content: `Thought: æˆ‘éœ€è¦åˆ†æäººå·¥æ™ºèƒ½åœ¨2024å¹´çš„å‘å±•è¶‹åŠ¿ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„ç ”ç©¶ä»»åŠ¡
Action: calculator  
Action Input: {"operation": "add", "a": 2024, "b": 5}`,
			Model: "demo-model",
			Usage: llm.Usage{TotalTokens: 50},
		},
		{
			Content: `Thought: æˆ‘å·²ç»è®¡ç®—äº†æœªæ¥5å¹´çš„æ—¶é—´èŒƒå›´ï¼Œç°åœ¨æˆ‘éœ€è¦åŸºäºæˆ‘çš„çŸ¥è¯†æä¾›è¯¦ç»†åˆ†æ
Final Answer: åŸºäºå¯¹äººå·¥æ™ºèƒ½å‘å±•çš„åˆ†æï¼Œ2024å¹´å‘ˆç°ä»¥ä¸‹å…³é”®è¶‹åŠ¿ï¼š

1. **å¤§è¯­è¨€æ¨¡å‹çš„æˆç†ŸåŒ–**: GPT-4å’Œå…¶ä»–å…ˆè¿›æ¨¡å‹åœ¨å„è¡Œä¸šä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨
2. **å¤šæ¨¡æ€AIçš„å…´èµ·**: æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘çš„ç»Ÿä¸€å¤„ç†èƒ½åŠ›æ˜¾è‘—æå‡  
3. **AIåŸºç¡€è®¾æ–½çš„å®Œå–„**: äº‘ç«¯AIæœåŠ¡å’Œè¾¹ç¼˜è®¡ç®—èƒ½åŠ›å¤§å¹…å¢å¼º
4. **ç›‘ç®¡æ¡†æ¶çš„å»ºç«‹**: å„å›½å¼€å§‹åˆ¶å®šAIæ²»ç†æ³•è§„å’Œä¼¦ç†æ ‡å‡†

æœªæ¥5å¹´(2025-2029)å½±å“é¢„æµ‹ï¼š
- AIå°†æˆä¸ºä¼ä¸šæ•°å­—åŒ–è½¬å‹çš„æ ¸å¿ƒé©±åŠ¨åŠ›
- é¢„è®¡AIå¸‚åœºè§„æ¨¡å°†ä»å½“å‰çš„1500äº¿ç¾å…ƒå¢é•¿åˆ°5000äº¿ç¾å…ƒ
- è‡ªåŠ¨åŒ–ç¨‹åº¦å°†æ˜¾è‘—æå‡ï¼ŒåŒæ—¶å‚¬ç”Ÿæ–°çš„å·¥ä½œå²—ä½
- AIå®‰å…¨å’Œå¯è§£é‡Šæ€§å°†æˆä¸ºæŠ€æœ¯å‘å±•é‡ç‚¹

è¿™ä¸€åˆ†æåŸºäºå½“å‰æŠ€æœ¯å‘å±•è½¨è¿¹å’Œå¸‚åœºè¶‹åŠ¿ï¼Œä¸ºå†³ç­–æä¾›å‚è€ƒã€‚`,
			Model: "demo-model",
			Usage: llm.Usage{TotalTokens: 200},
		},
	}

	return &mockLLMImpl{responses: responses, currentIndex: 0}
}

// mockLLMImpl æ¨¡æ‹ŸLLMå®ç°
type mockLLMImpl struct {
	responses    []llm.Response
	currentIndex int
}

func (m *mockLLMImpl) Call(ctx context.Context, messages []llm.Message, options *llm.CallOptions) (*llm.Response, error) {
	if m.currentIndex >= len(m.responses) {
		m.currentIndex = len(m.responses) - 1
	}

	response := m.responses[m.currentIndex]
	m.currentIndex++

	// æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
	time.Sleep(100 * time.Millisecond)

	return &response, nil
}

func (m *mockLLMImpl) Stream(ctx context.Context, messages []llm.Message, options *llm.CallOptions) (<-chan llm.StreamResponse, error) {
	// ç®€å•çš„æµå®ç°
	ch := make(chan llm.StreamResponse, 1)
	go func() {
		defer close(ch)
		response, _ := m.Call(ctx, messages, options)
		ch <- llm.StreamResponse{Delta: response.Content}
	}()
	return ch, nil
}

func (m *mockLLMImpl) CallStream(ctx context.Context, messages []llm.Message, options *llm.CallOptions) (<-chan llm.StreamResponse, error) {
	return m.Stream(ctx, messages, options)
}

// LLMæ¥å£çš„å…¶ä»–å¿…éœ€æ–¹æ³•
func (m *mockLLMImpl) GetModel() string                     { return "demo-model" }
func (m *mockLLMImpl) SupportsFunctionCalling() bool        { return false }
func (m *mockLLMImpl) GetContextWindowSize() int            { return 4096 }
func (m *mockLLMImpl) SetEventBus(eventBus events.EventBus) {}
func (m *mockLLMImpl) Close() error                         { return nil }

// ç¡®ä¿mockLLMImplå®ç°äº†LLMæ¥å£
var _ llm.LLM = (*mockLLMImpl)(nil)
